{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport random\nimport scipy as sp\nfrom tqdm import tqdm\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import Dataset\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport json\nfrom pathlib import Path\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage import io, transform\nfrom skimage.measure import label, regionprops\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image \nimport os\nimport sys\nimport cv2\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:36.705639Z","iopub.execute_input":"2021-06-09T08:22:36.706004Z","iopub.status.idle":"2021-06-09T08:22:39.311667Z","shell.execute_reply.started":"2021-06-09T08:22:36.705924Z","shell.execute_reply":"2021-06-09T08:22:39.310574Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  \n\ndef rle_encode(img):\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef multi_rle_encode(img):\n    labels = label(img)\n    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n        \ndef maskcsv_to_img(masks, img_name,shape=(768,768)):\n    masks_img = np.zeros((768,768))\n    boolean=masks['ImageId']==img_name\n    bins=masks.loc[boolean,'EncodedPixels']\n    bins=bins.tolist()\n    \n    for m in bins:\n        if str(m)==m:\n            masks_img=masks_img+rle_decode(m)\n            \n    masks_img=np.expand_dims(masks_img, -1)   \n    \n    return masks_img\n\ndef masks_as_image(groupix,shape=(768, 768)):\n    masks = np.zeros(shape, dtype = np.int)\n    \n    for m in groupix:\n        if str(m)==m:\n            masks += rle_decode(m)\n            \n    masks=np.expand_dims(masks, -1)\n    \n    return masks\n\ndef imshow_mask(img, mask):\n    img = img.numpy()\n    img = img.transpose((1, 2, 0))\n    img = np.clip(img, 0, 1)\n    \n    mask = mask.numpy()\n    mask = mask.transpose((1, 2, 0))\n    mask = np.clip(mask, 0, 1)\n    \n    fig, axs = plt.subplots(1,2, figsize=(15,30))\n    \n    axs[0].imshow(img)\n    axs[1].imshow(mask)\n    axis('off')\n\ndef clip_fin(gt):\n    return np.clip(gt.numpy().transpose((1, 2, 0)), 0, 1)\n\ndef imshow_gt_out(img, mask, mask_out):\n    img = clip_fin(img)\n    mask = clip_fin(mask)\n    mask_out = clip_fin(mask_out)\n    \n    fig, ax = plt.subplots(1,3, figsize=(10,30))\n    \n    tab1=[img,mask,mask_out]\n    tab2=['Original','Actual','Model']\n    \n    for i in range(3):\n        ax[i].imshow(tab1[i])\n        ax[i].set_title(tab2[i])\n        \n    axis('off')\n\ndef imshow_overlay(img, mask, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    img=clip_fin(img)\n    mask=clip_fin(mask)\n    \n    fig = plt.figure()\n    plt.imshow(mask_overlay(img, mask))\n\ndef mask_overlay(image, mask, color=(0, 1, 0)):\n    mask = np.dstack((mask, mask, mask)) * np.array(color)\n    weighted_sum = cv2.addWeighted(mask, 0.5, image, 0.5, 0.)\n    img = image.copy()\n    ind = mask[:, :, 1] > 0\n    img[ind] = weighted_sum[ind]    \n    return img","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:39.313291Z","iopub.execute_input":"2021-06-09T08:22:39.313605Z","iopub.status.idle":"2021-06-09T08:22:39.336661Z","shell.execute_reply.started":"2021-06-09T08:22:39.313576Z","shell.execute_reply":"2021-06-09T08:22:39.335761Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    \n    def __init__(self, ids, transform=None, mode='train'):\n        #Mode can take values : \n        # - train\n        # - val : to evaluate perf\n        # - test : for the submission\n        \n        IDs=list(ids.groupby('ImageId'))\n\n        self.ids =  [ID for ID, _ in IDs] \n        \n        self.masks = [mask['EncodedPixels'].values for _,mask in IDs]\n\n        self.trans = transform\n        \n        self.img_transform = transforms.Compose([transforms.ToTensor()])\n        \n        self.mode=mode\n        \n               \n    def __getitem__(self, idx):\n        \n        ID = self.ids[idx]\n        \n        if (self.mode == 'train'):\n            path = os.path.join('../input/airbus-ship-detection/train_v2',ID)\n        \n        elif(self.mode == 'validation'):\n            path = os.path.join('../input/airbus-ship-detection/train_v2',ID)\n            \n        else:\n            path = os.path.join('../input/airbus-ship-detection/test_v2',ID)\n            \n        image = imread(path)\n        \n        mask = masks_as_image(self.masks[idx])\n        \n        if (self.trans): \n            image, mask = self.trans(image, mask)\n            \n        if (self.mode == 'train'):\n            x=self.img_transform(image)\n            y=torch.from_numpy(np.moveaxis(mask, -1, 0)).float()\n            return x,y   \n        \n        elif (self.mode == 'validation'):\n            x=self.img_transform(image)\n            y=torch.from_numpy(np.moveaxis(mask, -1, 0)).float()\n            return x,y    \n            \n        else:\n            x=self.img_transform(image)\n            y=str(ID)\n            return x,y \n\n    def __len__(self):\n        return len(self.ids)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:39.338520Z","iopub.execute_input":"2021-06-09T08:22:39.338882Z","iopub.status.idle":"2021-06-09T08:22:39.351625Z","shell.execute_reply.started":"2021-06-09T08:22:39.338847Z","shell.execute_reply":"2021-06-09T08:22:39.350801Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# https://github.com/ternaus/robot-surgery-segmentation\n\ndef clip(img, dtype, maxval):\n    return np.clip(img, 0, maxval).astype(dtype)\n\nclass DualCompose:\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, x, mask=None):\n        for t in self.transforms:\n            x, mask = t(x, mask)\n        return x, mask\n\nclass ImageOnly:\n    def __init__(self, trans):\n        self.trans = trans\n\n    def __call__(self, x, mask=None):\n        return self.trans(x), mask\n\n\nclass VerticalFlip:\n    def __init__(self, prob=0.5):\n        self.prob = prob\n\n    def __call__(self, img, mask=None):\n        if random.random() < self.prob:\n            img = cv2.flip(img, 0)\n            if mask is not None:\n                mask = cv2.flip(mask, 0)\n        return img, mask\n\n\nclass HorizontalFlip:\n    def __init__(self, prob=0.5):\n        self.prob = prob\n\n    def __call__(self, img, mask=None):\n        if random.random() < self.prob:\n            img = cv2.flip(img, 1)\n            if mask is not None:\n                mask = cv2.flip(mask, 1)\n        return img, mask\n\n\nclass RandomFlip:\n    def __init__(self, prob=0.5):\n        self.prob = prob\n\n    def __call__(self, img, mask=None):\n        if random.random() < self.prob:\n            d = random.randint(-1, 1)\n            img = cv2.flip(img, d)\n            if mask is not None:\n                mask = cv2.flip(mask, d)\n        return img, mask\n\n\nclass Rotate:\n    def __init__(self, limit=90, prob=0.5):\n        self.prob = prob\n        self.limit = limit\n\n    def __call__(self, img, mask=None):\n        if random.random() < self.prob:\n            angle = random.uniform(-self.limit, self.limit)\n\n            height, width = img.shape[0:2]\n            mat = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1.0)\n            img = cv2.warpAffine(img, mat, (height, width),\n                                 flags=cv2.INTER_LINEAR,\n                                 borderMode=cv2.BORDER_REFLECT_101)\n            if mask is not None:\n                mask = cv2.warpAffine(mask, mat, (height, width),\n                                      flags=cv2.INTER_LINEAR,\n                                      borderMode=cv2.BORDER_REFLECT_101)\n\n        return img, mask\n\nclass RandomCrop:\n    def __init__(self, size):\n        self.h = size[0]\n        self.w = size[1]\n\n    def __call__(self, img, mask=None):\n        height, width, _ = img.shape\n\n        h_start = np.random.randint(0, height - self.h)\n        w_start = np.random.randint(0, width - self.w)\n\n        img = img[h_start: h_start + self.h, w_start: w_start + self.w,:]\n\n        assert img.shape[0] == self.h\n        assert img.shape[1] == self.w\n\n        if mask is not None:\n            if mask.ndim == 2:\n                mask = np.expand_dims(mask, axis=2)\n            mask = mask[h_start: h_start + self.h, w_start: w_start + self.w,:]\n\n        return img, mask\n\nclass CenterCrop:\n    def __init__(self, size):\n        self.height = size[0]\n        self.width = size[1]\n\n    def __call__(self, img, mask=None):\n        h, w, c = img.shape\n        dy = (h - self.height) // 2\n        dx = (w - self.width) // 2\n        y1 = dy\n        y2 = y1 + self.height\n        x1 = dx\n        x2 = x1 + self.width\n        img = img[y1:y2, x1:x2,:]\n        if mask is not None:\n            if mask.ndim == 2:\n                mask = np.expand_dims(mask, axis=2)\n            mask = mask[y1:y2, x1:x2,:]\n\n        return img, mask","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:39.353306Z","iopub.execute_input":"2021-06-09T08:22:39.353683Z","iopub.status.idle":"2021-06-09T08:22:39.377652Z","shell.execute_reply.started":"2021-06-09T08:22:39.353645Z","shell.execute_reply":"2021-06-09T08:22:39.376529Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Data augmentation\ntrain_transform = DualCompose([HorizontalFlip(), VerticalFlip(), RandomCrop((256,256,3))])\nval_transform = DualCompose([CenterCrop((512,512,3))])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:39.379179Z","iopub.execute_input":"2021-06-09T08:22:39.379613Z","iopub.status.idle":"2021-06-09T08:22:39.389547Z","shell.execute_reply.started":"2021-06-09T08:22:39.379572Z","shell.execute_reply":"2021-06-09T08:22:39.388764Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/c/airbus-ship-detection/discussion/62921\n\ntraincorr=pd.read_csv('../input/corruption/corruptedtrainimages.csv')\nremovaltrain=traincorr['ImageId']\n\ndf = pd.read_csv('../input/airbus-ship-detection/train_ship_segmentations_v2.csv')\ndf = df[~df['ImageId'].isin(removaltrain)]\n\nwith_ships = df.dropna()\nunique = with_ships.groupby('ImageId').size().reset_index(name='counts')\n\ntrain_id, val_id = train_test_split(unique, test_size=0.05, stratify=unique['counts'])\ntrain = pd.merge(with_ships, train_id)\nvalidation = pd.merge(with_ships, val_id)\n\ntrain_dataset = Dataset(train, transform=train_transform, mode='train')\nvalidation_dataset = Dataset(validation, transform=val_transform, mode='validation')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:39.390868Z","iopub.execute_input":"2021-06-09T08:22:39.391261Z","iopub.status.idle":"2021-06-09T08:22:45.579341Z","shell.execute_reply.started":"2021-06-09T08:22:39.391224Z","shell.execute_reply":"2021-06-09T08:22:45.578513Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def BCEDiceLoss(outputs, targets): \n    bce = nn.BCEWithLogitsLoss()\n    loss = bce(outputs, targets)\n    targets = (targets == 1.0).float().view(-1)\n    outputs = F.sigmoid(outputs).view(-1)\n    intersection = (outputs * targets).sum()\n    dice = 2.0 * (intersection + 1)/(targets.sum()+outputs.sum()+1)\n    loss -= torch.log(dice)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:45.580496Z","iopub.execute_input":"2021-06-09T08:22:45.580826Z","iopub.status.idle":"2021-06-09T08:22:45.586982Z","shell.execute_reply.started":"2021-06-09T08:22:45.580794Z","shell.execute_reply":"2021-06-09T08:22:45.586072Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Down(torch.nn.Module):\n    def __init__(self, input_channel, output_channel, down_size):\n        super(Down, self).__init__()\n        self.conv1 = torch.nn.Conv2d(input_channel, output_channel, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n        self.conv4 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn4 = torch.nn.BatchNorm2d(output_channel)\n        self.max_pool = torch.nn.MaxPool2d(2, 2)\n        self.relu = torch.nn.ReLU()\n        self.down_size = down_size\n\n    def forward(self, x):\n        if self.down_size:\n            x = self.max_pool(x)\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.relu(self.bn3(self.conv3(x)))\n        x = self.relu(self.bn4(self.conv4(x)))\n        return x\n\nclass Up(torch.nn.Module):\n    def __init__(self, prev_channel, input_channel, output_channel):\n        super(Up, self).__init__()\n        self.up_sampling = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n        self.conv1 = torch.nn.Conv2d(prev_channel + input_channel, output_channel, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n        self.conv4 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn4 = torch.nn.BatchNorm2d(output_channel)\n        self.relu = torch.nn.ReLU()\n\n    def forward(self, prev_feature_map, x):\n        x = self.up_sampling(x)\n        x = torch.cat((x, prev_feature_map), dim=1)\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.relu(self.bn3(self.conv3(x)))\n        x = self.relu(self.bn4(self.conv4(x)))\n        return x\n\n\nclass Final_UNet(torch.nn.Module):\n    def __init__(self):\n        super(Final_UNet, self).__init__()\n\n        self.down_1 = Down(3, 8, False)\n        self.down_2 = Down(8, 16, True)\n        self.down_3 = Down(16, 32, True)\n        self.down_4 = Down(32, 64, True)\n        self.down_5 = Down(64, 128, True)\n        self.down_6 = Down(128, 256, True)\n        self.down_7 = Down(256, 512, True)\n        self.down_8 = Down(512, 1024, True)\n\n        self.relu = torch.nn.ReLU()\n        self.mid_conv1 = torch.nn.Conv2d(1024, 1024, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(1024)\n        self.mid_conv2 = torch.nn.Conv2d(1024, 1024, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(1024)\n\n        self.up_1 = Up(512, 1024, 512)\n        self.up_2 = Up(256, 512, 256)\n        self.up_3 = Up(128, 256, 128)\n        self.up_4 = Up(64, 128, 64)\n        self.up_5 = Up(32, 64, 32)\n        self.up_6 = Up(16, 32, 16)\n        self.up_7 = Up(8, 16, 8)\n\n        self.last_conv = torch.nn.Conv2d(8, 1, 1, padding=0)\n\n    def forward(self, x):\n        self.x1 = self.down_1(x)\n        self.x2 = self.down_2(self.x1)\n        self.x3 = self.down_3(self.x2)\n        self.x4 = self.down_4(self.x3)\n        self.x5 = self.down_5(self.x4)\n        self.x6 = self.down_6(self.x5)\n        self.x7 = self.down_7(self.x6)\n        self.x8 = self.down_8(self.x7)\n        self.x8 = self.relu(self.bn1(self.mid_conv1(self.x8)))\n        self.x8 = self.relu(self.bn2(self.mid_conv2(self.x8)))\n        x = self.up_1(self.x7, self.x8)\n        x = self.up_2(self.x6, x)\n        x = self.up_3(self.x5, x)\n        x = self.up_4(self.x4, x)\n        x = self.up_5(self.x3, x)\n        x = self.up_6(self.x2, x)\n        x = self.up_7(self.x1, x)\n        x = self.last_conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:45.589021Z","iopub.execute_input":"2021-06-09T08:22:45.589512Z","iopub.status.idle":"2021-06-09T08:22:45.616699Z","shell.execute_reply.started":"2021-06-09T08:22:45.589477Z","shell.execute_reply":"2021-06-09T08:22:45.615947Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# PART 3 - CREATE TRAIN AND VALIDATION LOOPS","metadata":{}},{"cell_type":"code","source":"def train(lr, model, train_loader, valid_loader, n_epochs=8):\n      \n    device = torch.device(\"cuda\")\n    model = model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    epoch = 1\n    step = 0\n    \n    combloss=[]\n    meanloss=[]\n\n    for epoch in range(epoch, n_epochs + 1):\n        model.train()\n        tq = tqdm(total=len(train_loader) *  16)\n        \n        tq.set_description('Epoch ' + str(epoch))\n        \n        losses = []\n        \n        trainloader = train_loader\n        \n        for i, (inputs, targets) in enumerate(trainloader):\n            #Put inputs and targets to cuda\n            inputs = inputs.to(\"cuda\")\n            targets = targets.to(\"cuda\")\n            \n            #Compute loss\n            optimizer.zero_grad()\n            outputs = model.forward(inputs)\n            loss = BCEDiceLoss(outputs, targets)\n            batch_size = inputs.size(0)\n            loss.backward()\n            optimizer.step()\n            step += 1\n            tq.update(batch_size)\n            losses.append(loss.item())\n            current_loss = np.mean(losses[-50:]) # we average on the last 50 \n            tq.set_postfix(loss='{:.4f}'.format(current_loss))\n            \n            if i and i % 50 == 0:\n                meanloss.append([step,current_loss])\n                \n                \n        tq.close()\n\n        # Validation\n        combloss.append([step,validation(model, valid_loader)])\n    \n    return combloss,meanloss","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:50.744548Z","iopub.execute_input":"2021-06-09T08:22:50.744860Z","iopub.status.idle":"2021-06-09T08:22:50.756135Z","shell.execute_reply.started":"2021-06-09T08:22:50.744830Z","shell.execute_reply":"2021-06-09T08:22:50.755101Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def validation(model, valid_loader):\n    \n    losses = []\n    device = torch.device(\"cuda\")\n    model.eval()\n    \n    for inputs, targets in valid_loader:\n        inputs = inputs.to(\"cuda\")\n        targets = targets.to(\"cuda\")\n        outputs = model.forward(inputs)\n        loss = BCEDiceLoss(outputs, targets)\n        losses.append(loss.item())\n    \n    Loss = np.mean(losses)  \n    \n    return Loss","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:51.022587Z","iopub.execute_input":"2021-06-09T08:22:51.022858Z","iopub.status.idle":"2021-06-09T08:22:51.028685Z","shell.execute_reply.started":"2021-06-09T08:22:51.022833Z","shell.execute_reply":"2021-06-09T08:22:51.027447Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Training\nmodel=Final_UNet()\n\ncombloss,meanloss=train(lr = 1e-4,model=model,\n                        train_loader=torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True),\n                        valid_loader=torch.utils.data.DataLoader(validation_dataset, batch_size=4, shuffle=True),\n                        n_epochs = 8\n                        )","metadata":{"execution":{"iopub.status.busy":"2021-06-09T08:22:51.383651Z","iopub.execute_input":"2021-06-09T08:22:51.383972Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1:   0%|          | 0/39984 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n  \"See the documentation of nn.Upsample for details.\".format(mode))\n/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\nEpoch 1: 100%|█████████▉| 39974/39984 [25:56<00:00, 25.69it/s, loss=4.4958]\nEpoch 2: 100%|█████████▉| 39974/39984 [19:48<00:00, 33.62it/s, loss=3.3840]\nEpoch 3:  64%|██████▍   | 25616/39984 [12:44<07:00, 34.15it/s, loss=2.6480]","output_type":"stream"}]},{"cell_type":"markdown","source":"# PART 5 - SUBMISSION","metadata":{}},{"cell_type":"code","source":"from skimage.morphology import binary_opening, disk\n\ntest = pd.DataFrame({'ImageId': os.listdir('../input/airbus-ship-detection/test_v2'), 'EncodedPixels': None})\n\nloader = torch.utils.data.DataLoader(dataset=Dataset(test, mode='test'), batch_size=2)\n    \nout = []\n\nfor batch_num, (inputs, paths) in enumerate(tqdm(loader, desc='Test')):\n    inputs = inputs.cuda()\n    outputs = model(inputs)\n    \n    for i, image_name in enumerate(paths):\n        mask = F.sigmoid(outputs[i,0]).data.detach().cpu().numpy()\n        cur_seg = binary_opening(mask>0.5, disk(2))\n        cur_rles = multi_rle_encode(cur_seg)\n        if len(cur_rles)>0:\n            for c_rle in cur_rles:\n                out += [{'ImageId': image_name, 'EncodedPixels': c_rle}]\n        else:\n            out += [{'ImageId': image_name, 'EncodedPixels': None}]\n        \nsubmission = pd.DataFrame(out)[['ImageId', 'EncodedPixels']]\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:02:41.123706Z","iopub.status.idle":"2021-06-09T01:02:41.124457Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1:   1%|          | 384/40432 [00:30<24:41, 27.04it/s, loss=5.7994]","output_type":"stream"}]}]}